# FaaS Cold Start Scheduler Simulation

This project is a **practical, real-world simulation** of a Function-as-a-Service (FaaS) platform built with **Docker and Python**.  
It demonstrates and tests different **container scheduling strategies** to mitigate cold starts, inspired by the research paper  
**"LCS: Alleviating Total Cold Start Latency in Serverless Applications with LRU Warm Container Approach."**

---

## ğŸš€ Features

- **LCS (Least Recently Used)**: The proposed strategy that maximizes the warm pool by reusing the oldest idle container.
- **MRU (Most Recently Used)**: A cost-efficient strategy that picks the newest idle container.
- **Strategy Switching:** Change scheduling strategies dynamically via an API endpoint.
- **Affinity Scheduling:** Separate container pools per function (e.g., `function-a`, `function-b`).
- **Concurrency Limits:** Configurable max concurrent containers per function.
- **Request Queuing:** Requests beyond concurrency limit are queued, not dropped.
- **Dynamic Pool Creation:** Unknown functions create new pools automatically.
- **Scale-to-Zero (Janitor):** Idle containers are removed automatically after `WARM_TIME` seconds.
- **Statistics API:** `/stats` endpoint provides detailed JSON metrics (cold/warm starts, queues, etc.).

---
## ğŸ“ Project Structure
```
.
â”œâ”€â”€ my_function/
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ exp1_lru.json
â”‚   â””â”€â”€ exp1_mru.json
â”œâ”€â”€ scheduler.py
â”œâ”€â”€ run_experiment.sh
â”œâ”€â”€ results.html
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```


---

## ğŸ§© Prerequisites

- **Docker Desktop** (or Docker Engine)
- **Python 3.7+**
- **jq** (for JSON processing)

**Install jq:**  
- Ubuntu/Debian â†’ `sudo apt-get install jq`  
- macOS â†’ `brew install jq`

---

## âš™ï¸ Setup & Installation

### 1ï¸âƒ£ Clone the repository
```bash
git clone <your-repo-url>
cd coldBootFirstSem
```

### 2ï¸âƒ£ Build the function container
```bash
docker build -t faas-function:latest ./my_function
```

### 3ï¸âƒ£ Set up Python environment
```bash
python3 -m venv venv
source venv/bin/activate  # (Windows: venv\Scripts\activate)
```

### 4ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

---

## â–¶ï¸ How to Run the Simulation

The simulation needs **two terminals**.

### ğŸ–¥ï¸ Terminal 1: Start the Scheduler
```bash
python3 scheduler.py
```
Expected Output:
```
Starting Scheduler Service...
Connected to Docker daemon.
JANITOR: Starting up...
Starting API server on http://127.0.0.1:8080 .
```

### ğŸ§ª Terminal 2: Run the Test Script
Make it executable once:
```bash
chmod +x run_experiment.sh
```

### Run
```bash
./run_experiment.sh <strategy> <exp_no> <size/5>
```

#### Run with LCS:
```bash
./run_experiment.sh lru 1 10
```

#### Run with MRU:
```bash
./run_experiment.sh mru 1 10
```

Each test runs 4 workloads and outputs stats to JSON (`results/<exp_no>_<strategy>.json`).

---

## ğŸ“Š Understanding the Output

Example (Test 3 - Affinity Test):

**LCS (Least Recently Used):**
```json
{
  "total_cold_starts": 5,
  "total_warm_starts": 3,
  "total_requests_queued": 0
}
```

**MRU (Most Recently Used):**
```json
{
  "total_cold_starts": 6,
  "total_warm_starts": 1,
  "total_requests_queued": 1
}
```

## ğŸ“Š Visualization Dashboard
Run:
```bash
python3 -m http.server 8000
```
Open:
```
http://localhost:8000/results.html
```

---

ğŸ“ˆ **Analysis:** LCS results in fewer cold starts (5 vs. 6) and higher warm reuse (3 vs. 1).

---

## âš™ï¸ Configuration

Edit constants in `scheduler.py`:

| Variable | Description |
|-----------|-------------|
| `WARM_TIME` | Idle time (seconds) before a container is stopped |
| `JANITOR_SLEEP` | Interval for Janitor checks |
| `FUNCTION_POOLS` | Default concurrency per function |

---

## ğŸ§  Reference

**Paper:** *"LCS: Alleviating Total Cold Start Latency in Serverless Applications with LRU Warm Container Approach."*  
This simulation implements and compares that scheduling logic in a real Docker-based setup.

---

## ğŸ§¾ License

MIT License Â© 2025